{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in the calibration data\n",
      "Run pipeline for 'videos_output/project_video.mp4'...\n",
      "Moviepy - Building video videos_output/project_video.mp4.\n",
      "Moviepy - Writing video videos_output/project_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready videos_output/project_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import VideoFileClip\n",
    "# Parameters for calibration\n",
    "mtx = []\n",
    "dist = []\n",
    "calibration_file = \"calibration_pickle.p\"\n",
    "# Parameters for gradient threshold\n",
    "ksize = 7\n",
    "gradx_thresh = (25, 255)\n",
    "grady_thresh = (25, 255)\n",
    "magni_thresh = (25, 255)\n",
    "dir_thresh = (0., 0.09)\n",
    "hls_thresh = (125, 255)\n",
    "def get_points_for_calibration(nx, ny):\n",
    "    # Prepare object points\n",
    "    objp = np.zeros((ny*nx,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "    # Arrays to store object points and image points from all the images\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('camera_cal/calibration*.jpg')\n",
    "    for idx, fname in enumerate(images):\n",
    "        # Read image\n",
    "        img = cv2.imread(fname)\n",
    "        # Convert image in grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # Find chessboard corners (for an 9x6 board)\n",
    "        ret, corners = cv2.findChessboardCorners(img, (nx,ny), None)\n",
    "        if (ret == True):\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            # Draw and display the corners\n",
    "            cv2.drawChessboardCorners(img, (nx,ny), corners, ret)\n",
    "            cv2.imwrite('./output_images/calibration/corners_found' + str(idx) + '.jpg', img)\n",
    "    return (objpoints, imgpoints)\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Calculate directional gradient\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    x = 1 if orient == 'x' else 0\n",
    "    y = 1 if orient == 'y' else 0\n",
    "    sobel = cv2.Sobel(gray, cv2.CV_64F, x, y, ksize=sobel_kernel)\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    sobel_scaled = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Apply threshold\n",
    "    grad_binary = np.zeros_like(sobel_scaled)\n",
    "    grad_binary[(sobel_scaled >= thresh[0]) & (sobel_scaled <= thresh[1])] = 1\n",
    "    return grad_binary\n",
    "def mag_thresh(img, sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Calculate gradient magnitude\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    mag = np.sqrt(np.add(np.square(sobelx), np.square(sobely)))\n",
    "    sobel_scaled = np.uint8(255*mag/np.max(mag))\n",
    "    # Apply threshold\n",
    "    mag_binary = np.zeros_like(sobel_scaled)\n",
    "    mag_binary[(sobel_scaled >= thresh[0]) & (sobel_scaled <= thresh[1])] = 1\n",
    "    return mag_binary\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Calculate gradient direction\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    direction = np.arctan2(abs_sobely, abs_sobely)\n",
    "    # Apply threshold\n",
    "    dir_binary = np.zeros_like(direction)\n",
    "    dir_binary[(direction >= thresh[0]) & (direction <= thresh[1])] = 1\n",
    "    return dir_binary\n",
    "def hls_threshold(img, thresh=(0, 255)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    S_channel = hls[:,:,2]\n",
    "    color_binary = np.zeros_like(S_channel)\n",
    "    color_binary[(S_channel >= thresh[0]) & (S_channel <= thresh[1])] = 1\n",
    "    return color_binary\n",
    "def color_gradient_threshold(img):\n",
    "    # Apply color gradient (S channel)\n",
    "    hls_binary = hls_threshold(img, thresh=hls_thresh)\n",
    "    # Apply gradient thresholding functions\n",
    "    gradx = abs_sobel_thresh(img, orient='x', sobel_kernel=ksize, thresh=gradx_thresh)\n",
    "    grady = abs_sobel_thresh(img, orient='y', sobel_kernel=ksize, thresh=grady_thresh)\n",
    "    mag_binary = mag_thresh(img, sobel_kernel=ksize, thresh=magni_thresh)\n",
    "    dir_binary = dir_threshold(img, sobel_kernel=ksize, thresh=dir_thresh)\n",
    "    # Combine gradient & color thresholds\n",
    "    color_binary = np.dstack((np.zeros_like(dir_binary), dir_binary, dir_binary)) * 255\n",
    "    gradient_binary = np.zeros_like(dir_binary)\n",
    "    gradient_binary[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[(gradient_binary == 1) | (hls_binary == 1)] = 1\n",
    "    return combined\n",
    "def region_of_interest(img):\n",
    "    # Set vertices for the mask\n",
    "    imshape = img.shape # x: imshape[1], y: imshape[0]\n",
    "    left_bottom = (0.15*imshape[1], imshape[0])\n",
    "    left_top = (0.45*imshape[1], 0.6*imshape[0])\n",
    "    right_top = (0.60*imshape[1], 0.6*imshape[0])\n",
    "    right_bottom = (0.9*imshape[1], imshape[0])\n",
    "    vertices = np.array([[left_bottom, left_top, right_top, right_bottom]], dtype=np.int32)\n",
    "    # Define blank mask to start with\n",
    "    mask = np.zeros_like(img)\n",
    "    # Define a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on the image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    # Fill pixels inside the polygon defined by \"vertices\" with the fill color\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    # Return the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "def perspective_transform(img):\n",
    "    # From trapezoidale shape on straight lines...\n",
    "    src = np.float32([[519, 502], [765, 502], [1029, 668], [275, 668]])\n",
    "    # ...to rectangle\n",
    "    dst = np.float32([[275, 502], [1029, 502], [1029, 668], [275, 668]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    #Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    return (cv2.warpPerspective(img, M, img.shape[1::-1], flags=cv2.INTER_LINEAR), Minv)\n",
    "\n",
    "\n",
    "def sliding_windows_polyfit(img, previous_left_fit=None, previous_right_fit=None):\n",
    "\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.uint8(np.dstack((img, img, img))*255)\n",
    "\n",
    "    # Get indices of all nonzero pixels along x and y axis\n",
    "    nonzero = img.nonzero()\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "\n",
    "    # Set margin for searching\n",
    "    margin = 100\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Look for lines from scratch ('blind search')\n",
    "    if (previous_left_fit is None or previous_right_fit is None):\n",
    "        # Compute the histogram of the lower half image. It gives us the 2 pics where the lanes are located.\n",
    "        histogram = np.sum(img[int(img.shape[0]/2):,:], axis=0)\n",
    "        # Separate the left part of the histogram from the right one. This is our starting point.\n",
    "        midpoint = np.int(histogram.shape[0]/2)\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base =  np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        # Split the image in 9 horizontal strips\n",
    "        n_windows = 9\n",
    "        # Set height of windows\n",
    "        window_height = int(img.shape[0]/n_windows)\n",
    "        # Set minimum number of pixels found to recenter window\n",
    "        minpix = 50\n",
    "\n",
    "        # Current positions to be updated for each window\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base\n",
    "\n",
    "        # Step through the windows one by one\n",
    "        for window in range(n_windows):\n",
    "            # Compute the windows boundaries\n",
    "            win_y_low = img.shape[0] - (window+1)*window_height\n",
    "            win_y_high = img.shape[0] - window*window_height\n",
    "            win_leftx_low = leftx_current - margin\n",
    "            win_leftx_high = leftx_current + margin\n",
    "            win_rightx_low = rightx_current - margin\n",
    "            win_rightx_high = rightx_current + margin\n",
    "\n",
    "            # Draw the windows on the visualization image\n",
    "            cv2.rectangle(out_img, (win_leftx_low,win_y_low), (win_leftx_high,win_y_high), (0,255,0), 2)\n",
    "            cv2.rectangle(out_img, (win_rightx_low,win_y_low), (win_rightx_high,win_y_high), (0,255,0), 2)\n",
    "\n",
    "            # Identify non zero pixels within left and right windows\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_leftx_low) & (nonzerox < win_leftx_high)).nonzero()[0]\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_rightx_low) & (nonzerox < win_rightx_high)).nonzero()[0]\n",
    "\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "\n",
    "            # If non zeros pixels > minpix, recenter the next window on their mean\n",
    "            if (len(good_left_inds) > minpix):\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if (len(good_right_inds) > minpix):\n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Use last polynomial fit\n",
    "    else:\n",
    "        # Compute the windows boundaries\n",
    "        previous_left_x = previous_left_fit[0]*nonzeroy**2 + previous_left_fit[1]*nonzeroy + previous_left_fit[2]\n",
    "        win_leftx_low = previous_left_x - margin\n",
    "        win_leftx_high =  previous_left_x + margin\n",
    "        previous_right_x = previous_right_fit[0]*nonzeroy**2 + previous_right_fit[1]*nonzeroy + previous_right_fit[2]\n",
    "        win_rightx_low = previous_right_x - margin\n",
    "        win_rightx_high =  previous_right_x + margin\n",
    "        # Identify non zero pixels within left and right windows\n",
    "        good_left_inds = ((nonzerox >= win_leftx_low) & (nonzerox < win_leftx_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzerox >= win_rightx_low) & (nonzerox < win_rightx_high)).nonzero()[0]\n",
    "\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    return (out_img, left_fit, right_fit)\n",
    "\n",
    "def compute_curvature_radius(img, leftx, rightx, lefty, righty):\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    left_fit = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    # Choose point to compute curvature just in front of the car\n",
    "    yvalue = img.shape[0]\n",
    "    # Compute curvature radius\n",
    "    left_curv_radius = ((1 + (2*left_fit[0]*yvalue + left_fit[1])**2)**1.5) / (2*np.absolute(left_fit[0]))\n",
    "    right_curv_radius = ((1 + (2*right_fit[0]*yvalue + right_fit[1])**2)**1.5) / (2*np.absolute(right_fit[0]))\n",
    "    return (left_curv_radius, right_curv_radius)\n",
    "\n",
    "def draw_lane(img, warped, Minv, left_fit, right_fit):\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0]))\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(img, 1, newwarp, 0.3, 0)\n",
    "    return result\n",
    "def draw_data(img, polyfit_img, gradient_binary, left_curv_radius, right_curv_radius):\n",
    "    result = np.copy(img)\n",
    "    # Take the mean of the left and right riadus\n",
    "    mean_curv_radius = np.mean([left_curv_radius, right_curv_radius])\n",
    "    # Add text to the original image\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    text = 'Curve radius: ' + '{:04.2f}'.format(mean_curv_radius) + 'm'\n",
    "    cv2.putText(result, text, (40,70), font, 1.5, (200,255,155), 2, cv2.LINE_AA)\n",
    "    # Add transformed images to the original image\n",
    "    mask = np.ones_like(polyfit_img)*255\n",
    "    img_1 = cv2.resize(polyfit_img, None, fx=0.3, fy=0.3, interpolation=cv2.INTER_AREA)\n",
    "    gradient = np.uint8(np.dstack((gradient_binary, gradient_binary, gradient_binary))*255)\n",
    "    img_2 = cv2.resize(gradient, None, fx=0.3, fy=0.3, interpolation=cv2.INTER_AREA)\n",
    "    offset = 50\n",
    "    endy_img_1 = offset+img_1.shape[0]\n",
    "    endy_img_2 = endy_img_1+img_2.shape[0]+20\n",
    "    starty_img_2 = endy_img_1+20\n",
    "    endx = polyfit_img.shape[1]-offset\n",
    "    startx = endx-img_1.shape[1]\n",
    "    mask[offset:endy_img_1, startx:endx] = img_1\n",
    "    mask[starty_img_2:endy_img_2, startx:endx] = img_2\n",
    "    return cv2.bitwise_and(result, mask)\n",
    "def save_image_transform(original, transformed, is_gray, file_name):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(original)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    if (is_gray == True):\n",
    "        ax2.imshow(transformed, cmap='gray')\n",
    "    else:\n",
    "        ax2.imshow(transformed)\n",
    "    ax2.set_title('Result Image', fontsize=30)\n",
    "    plt.savefig('./output_images/' + file_name + '.jpg')\n",
    "    plt.show()\n",
    "\n",
    "class Line:\n",
    "    def __init__(self, max_lines=5):\n",
    "        # Was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # Max number of last lines\n",
    "        self.max_lines = max_lines\n",
    "        # Polynomial coefficients for the most recent fit\n",
    "        self.recent_fit = []\n",
    "        # Polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None\n",
    "\n",
    "    def reset(self):\n",
    "        del self.recent_fit[:]\n",
    "\n",
    "    def store_lines(self, left_fit, right_fit):\n",
    "        if (left_fit is None or right_fit is None):\n",
    "            self.detected = False\n",
    "            # Remove the oldest fit from the history\n",
    "            self.recent_fit.pop(0)\n",
    "        else:\n",
    "            self.detected = True\n",
    "            if (len(self.recent_fit) == self.max_lines):\n",
    "                # Remove the oldest fit from the history\n",
    "                self.recent_fit.pop(0)\n",
    "            # Add the new lines\n",
    "            self.recent_fit.append((left_fit, right_fit))\n",
    "\n",
    "        # Update best fit\n",
    "        self.best_fit = np.average(self.recent_fit, axis=0)\n",
    "\n",
    "    def process_img(self, img):\n",
    "        ### 1. Distortion correction ###\n",
    "        undistorted = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "        ### 2. Gradient threshold ###\n",
    "        gradient = color_gradient_threshold(undistorted)\n",
    "\n",
    "        ### 2. Region of interest ###\n",
    "        masked_image = region_of_interest(gradient)\n",
    "\n",
    "        ### 3. Perspective transformation ###\n",
    "        warped, Minv = perspective_transform(masked_image)\n",
    "\n",
    "        ### 4. Detect lines and store it ###\n",
    "        if (self.detected):\n",
    "            polyfit_image, left_fit, righ_fit = sliding_windows_polyfit(warped, self.best_fit[0], self.best_fit[1])\n",
    "        else:\n",
    "            polyfit_image, left_fit, righ_fit = sliding_windows_polyfit(warped)\n",
    "        self.store_lines(left_fit, righ_fit)\n",
    "\n",
    "        ### 5. Visualize lane found back on to the road ###\n",
    "        return draw_lane(img, warped, Minv, left_fit, righ_fit)\n",
    "\n",
    "        ### 6. Compute radius and display on image\n",
    "        left_curv_radius, right_curv_radius = compute_curvature_radius(lanes, leftx, rightx, lefty, righty)\n",
    "        return draw_data(lanes, polyfit_image, gradient, left_curv_radius, right_curv_radius)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ### Camera calibration ###\n",
    "    if os.path.exists(calibration_file):\n",
    "        print(\"Read in the calibration data\")\n",
    "        calibration_pickle = pickle.load(open(calibration_file, \"rb\"))\n",
    "        mtx = calibration_pickle[\"mtx\"]\n",
    "        dist = calibration_pickle[\"dist\"]\n",
    "    else:\n",
    "        print(\"Calibrate camera...\")\n",
    "        objpoints, imgpoints = get_points_for_calibration(9, 6)\n",
    "        img = cv2.imread('./test_images/test1.jpg')\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[1::-1], None, None)\n",
    "        print(\"Save the camera calibration result for later use\")\n",
    "        calibration_pickle = {}\n",
    "        calibration_pickle[\"mtx\"] = mtx\n",
    "        calibration_pickle[\"dist\"] = dist\n",
    "        pickle.dump(calibration_pickle, open(calibration_file, \"wb\"))\n",
    "    # Create directory if it does not exist\n",
    "    output_video_dir = \"videos_output/\"\n",
    "    if not os.path.isdir(output_video_dir):\n",
    "        os.makedirs(output_video_dir)\n",
    "    video_output_1 = output_video_dir + 'project_video.mp4'\n",
    "    video_output_2 = output_video_dir + 'challenge_video.mp4'\n",
    "\n",
    "    print(\"Run pipeline for '\" + video_output_1 + \"'...\")\n",
    "    line = Line()\n",
    "    video_input = VideoFileClip(\"project_video.mp4\").subclip(0,2)\n",
    "    processed_video = video_input.fl_image(line.process_img)\n",
    "    processed_video.write_videofile(video_output_1, audio=False)\n",
    "\n",
    "\n",
    "    '''print(\"Run pipeline for '\" + video_output_2 + \"'...\")\n",
    "    video_input = VideoFileClip(\"project_video.mp4\")\n",
    "    processed_video = video_input.fl_image(pipeline)\n",
    "    processed_video.write_videofile(video_output_2, audio=False)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (carnd)",
   "language": "python",
   "name": "carnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
